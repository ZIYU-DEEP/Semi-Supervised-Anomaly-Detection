{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../dataset/')\n",
    "sys.path.append('../network/')\n",
    "sys.path.append('../model/')\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import torch\n",
    "import logging\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "from main_loading import *\n",
    "from main_network import *\n",
    "from main_model_rec import *\n",
    "from main_model_one_class import *\n",
    "from scipy.spatial import KDTree\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:1'\n",
    "root = '/net/leksai/data/FashionMNIST'\n",
    "rec_model_path = '/net/leksai/nips/model/rec/fmnist/rec_unsupervised_[2]_[]_[0.0]/net_fmnist_LeNet_rec_eta_100_epochs_150_batch_128/model.tar'\n",
    "oc_model_path = '/net/leksai/nips/model/one_class/fmnist/one_class_unsupervised_[2]_[]_[1]_[0.0]/net_fmnist_LeNet_one_class_eta_100_epochs_150_batch_128/model.tar'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Only the Encoder Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## For One-Class Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneClassEncoder:\n",
    "    def __init__(self):\n",
    "        self.net = None\n",
    "        self.net_name = None\n",
    "\n",
    "    def set_network(self, net_name):\n",
    "        self.net_name = net_name\n",
    "        self.net = build_network(net_name)\n",
    "\n",
    "    def load_model(self, model_path, map_location):\n",
    "        model_dict = torch.load(model_path, map_location=map_location)\n",
    "        self.c = model_dict['c']\n",
    "        self.net.load_state_dict(model_dict['net_dict'])\n",
    "\n",
    "    def test(self, train, dataset, device, batch_size, n_jobs_dataloader):\n",
    "        if train:\n",
    "            all_loader, _ = dataset.loaders(batch_size=batch_size,\n",
    "                                            num_workers=n_jobs_dataloader)\n",
    "        else:\n",
    "            all_loader = dataset.loaders(batch_size=batch_size,\n",
    "                                         num_workers=n_jobs_dataloader)\n",
    "        net = self.net.to(device)\n",
    "        criterion = nn.MSELoss(reduction='none')\n",
    "        \n",
    "        n_batches = 0\n",
    "        X_pred_list = []\n",
    "        net.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data in all_loader:\n",
    "                X, y, idx = data\n",
    "                X, y, idx = X.to(device), y.to(device), idx.to(device)\n",
    "\n",
    "                X_pred = net(X)\n",
    "                X_pred_list += X_pred\n",
    "        \n",
    "        return np.array(X_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "oc_encoder = OneClassEncoder()\n",
    "oc_encoder.set_network('fmnist_LeNet_one_class')\n",
    "oc_encoder.load_model(oc_model_path, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## For Reconstruction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecEncoder:\n",
    "    def __init__(self):\n",
    "\n",
    "        self.net_name = None\n",
    "        self.net = None\n",
    "        self.ae_net = None\n",
    "\n",
    "\n",
    "    def set_network(self, net_name: str='fmnist_LeNet_one_class'):\n",
    "        \"\"\"\n",
    "        Set the network structure for the model.\n",
    "        The key here is to initialize <self.net>.\n",
    "        \"\"\"\n",
    "        self.net_name = net_name\n",
    "        self.net = build_network(net_name)\n",
    "        self.ae_net = build_network('fmnist_LeNet_rec')\n",
    "\n",
    "    def load_model(self,\n",
    "                   model_path,\n",
    "                   map_location='cuda:1'):\n",
    "        \"\"\"\n",
    "        Load the trained model for the model.\n",
    "        The key here is to initialize <self.c>.\n",
    "        \"\"\"\n",
    "        # Load the general model\n",
    "        model_dict = torch.load(model_path, map_location=map_location)\n",
    "        self.ae_net.load_state_dict(model_dict['net_dict'])\n",
    "        \n",
    "        # Obtain the net dictionary\n",
    "        net_dict = self.net.state_dict()\n",
    "        ae_net_dict = self.ae_net.state_dict()\n",
    "        \n",
    "        # Filter out decoder network keys\n",
    "        ae_net_dict = {k: v for k, v in ae_net_dict.items() if k in net_dict}\n",
    "        \n",
    "        # Overwrite values in the existing state_dict\n",
    "        net_dict.update(ae_net_dict)\n",
    "\n",
    "        # Load the new state_dict\n",
    "        self.net.load_state_dict(net_dict)\n",
    "        \n",
    "\n",
    "    def save_model(self, export_model, save_ae=True):\n",
    "        net_dict = self.net.state_dict()\n",
    "        torch.save({'net_dict': net_dict}, export_model)\n",
    "    \n",
    "    def test(self, train, dataset, device, batch_size, n_jobs_dataloader):\n",
    "        if train:\n",
    "            all_loader, _ = dataset.loaders(batch_size=batch_size,\n",
    "                                            num_workers=n_jobs_dataloader)\n",
    "        else:\n",
    "            all_loader = dataset.loaders(batch_size=batch_size,\n",
    "                                         num_workers=n_jobs_dataloader)\n",
    "        net = self.net.to(device)\n",
    "        criterion = nn.MSELoss(reduction='none')\n",
    "        \n",
    "        n_batches = 0\n",
    "        X_pred_list = []\n",
    "        net.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data in all_loader:\n",
    "                X, y, idx = data\n",
    "                X, y, idx = X.to(device), y.to(device), idx.to(device)\n",
    "\n",
    "                X_pred = net(X)\n",
    "                X_pred_list += X_pred\n",
    "        \n",
    "        return np.array(X_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_encoder = RecEncoder()\n",
    "rec_encoder.set_network()\n",
    "rec_encoder.load_model(rec_model_path, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict_train = {}\n",
    "dataset_dict_all = {}\n",
    "name_list = ['tshirt', 'trouser', 'pullover', 'dress', 'coat',\n",
    "             'sandal', 'shirt', 'sneaker', 'bag', 'boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset for you!\n",
      "Almost loaded!\n",
      "Loading dataset for you!\n",
      "Almost loaded!\n",
      "Loading dataset for you!\n",
      "Almost loaded!\n",
      "Loading dataset for you!\n",
      "Almost loaded!\n",
      "Loading dataset for you!\n",
      "Almost loaded!\n",
      "Loading dataset for you!\n",
      "Almost loaded!\n",
      "Loading dataset for you!\n",
      "Almost loaded!\n",
      "Loading dataset for you!\n",
      "Almost loaded!\n",
      "Loading dataset for you!\n",
      "Almost loaded!\n",
      "Loading dataset for you!\n",
      "Almost loaded!\n"
     ]
    }
   ],
   "source": [
    "for i, name in enumerate(name_list):\n",
    "    dataset_dict_train[name] = load_dataset(loader_name='fmnist',\n",
    "                                            root=root,\n",
    "                                            label_normal=(i,),\n",
    "                                            ratio_abnormal=0)\n",
    "    dataset_dict_all[name] = load_dataset(loader_name='fmnist_eval',\n",
    "                                           root=root,\n",
    "                                           label_eval=(i,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Latent Vector Obtaining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let's use the unsupervised model of `pullover` as feature extractor, meaning that the latent space are defined from the neural weights of the unsupervised model of `pullover`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dict_train = {'oc':{}, 'rec':{}}\n",
    "latent_dict_all = {'oc':{}, 'rec':{}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## For One Class Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in name_list:\n",
    "    dataset_train = dataset_dict_train[name]\n",
    "    data_train = oc_encoder.test(True, dataset_train, device, 6000, 0)\n",
    "    data_train = np.array([x.cpu().numpy() for x in data_train])\n",
    "    latent_dict_train['oc'][name] = data_train\n",
    "    \n",
    "    dataset_all = dataset_dict_all[name]\n",
    "    data_all = oc_encoder.test(False, dataset_all, device, 7000, 0)\n",
    "    data_all = np.array([x.cpu().numpy() for x in data_all])\n",
    "    latent_dict_all['oc'][name] = data_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## For Rec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in name_list:\n",
    "    dataset_train = dataset_dict_train[name]\n",
    "    data_train = rec_encoder.test(True, dataset_train, device, 6000, 0)\n",
    "    data_train = np.array([x.cpu().numpy() for x in data_train])\n",
    "    latent_dict_train['rec'][name] = data_train\n",
    "    \n",
    "    dataset_all = dataset_dict_all[name]\n",
    "    data_all = rec_encoder.test(False, dataset_all, device, 7000, 0)\n",
    "    data_all = np.array([x.cpu().numpy() for x in data_all])\n",
    "    latent_dict_all['rec'][name] = data_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for KL Divergence by KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.spatial import KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cited from https://github.com/nhartland/KL-divergence-estimators\n",
    "\n",
    "def knn_distance(point, sample, k):\n",
    "    \"\"\" \n",
    "    Euclidean distance from `point` to it's `k`-Nearest\n",
    "    Neighbour in `sample` \n",
    "    \"\"\"\n",
    "    norms = np.linalg.norm(sample-point, axis=1)\n",
    "    return np.sort(norms)[k]\n",
    "\n",
    "\n",
    "def verify_sample_shapes(s1, s2, k):\n",
    "    # Expects [N, D]\n",
    "    assert(len(s1.shape) == len(s2.shape) == 2)\n",
    "    # Check dimensionality of sample is identical\n",
    "    assert(s1.shape[1] == s2.shape[1])\n",
    "    \n",
    "    \n",
    "def skl_estimator(s1, s2, k=1):\n",
    "    \"\"\" \n",
    "    KL-Divergence estimator using scikit-learn's NearestNeighbours.\n",
    "    Inputs:\n",
    "        s1: (N_1,D) Sample drawn from distribution P\n",
    "        s2: (N_2,D) Sample drawn from distribution Q\n",
    "        k: Number of neighbours considered (default 1)\n",
    "    return: \n",
    "        estimated D(P|Q)\n",
    "    \"\"\"\n",
    "    verify_sample_shapes(s1, s2, k)\n",
    "\n",
    "    n, m = len(s1), len(s2)\n",
    "    d = float(s1.shape[1])\n",
    "    D = np.log(m / (n - 1))\n",
    "\n",
    "    s1_neighbourhood = NearestNeighbors(k + 1, 10).fit(s1)\n",
    "    s2_neighbourhood = NearestNeighbors(k, 10).fit(s2)\n",
    "\n",
    "    for p1 in s1:\n",
    "        s1_distances, indices = s1_neighbourhood.kneighbors([p1], k + 1)\n",
    "        s2_distances, indices = s2_neighbourhood.kneighbors([p1], k)\n",
    "        rho = s1_distances[0][- 1]\n",
    "        nu = s2_distances[0][- 1]\n",
    "        D += (d / n) * np.log(nu / rho)\n",
    "    return D\n",
    "\n",
    "\n",
    "def scipy_estimator(s1, s2, k=1):\n",
    "    \"\"\" KL-Divergence estimator using scipy's KDTree\n",
    "        s1: (N_1,D) Sample drawn from distribution P\n",
    "        s2: (N_2,D) Sample drawn from distribution Q\n",
    "        k: Number of neighbours considered (default 1)\n",
    "        return: estimated D(P|Q)\n",
    "    \"\"\"\n",
    "    verify_sample_shapes(s1, s2, k)\n",
    "\n",
    "    n, m = len(s1), len(s2)\n",
    "    d = float(s1.shape[1])\n",
    "    D = np.log(m / (n - 1))\n",
    "\n",
    "    nu_d,  nu_i   = KDTree(s2).query(s1, k)\n",
    "    rho_d, rhio_i = KDTree(s1).query(s1, k+1)\n",
    "\n",
    "    # KTree.query returns different shape in k==1 vs k > 1\n",
    "    if k > 1:\n",
    "        D += (d/n)*np.sum(np.log(nu_d[::, -1] / rho_d[::, -1]))\n",
    "    else:\n",
    "        D += (d/n)*np.sum(np.log(nu_d / rho_d[::, -1]))\n",
    "\n",
    "    return D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Joint KL Divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## For One Class Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load for extra data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "pullover_train = latent_dict_train['oc']['pullover']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pullover_test = load_dataset(loader_name='fmnist_eval',\n",
    "                                     root=root,\n",
    "                                     label_eval=(2,),\n",
    "                                     test_eval=True)\n",
    "pullover_test = oc_encoder.test(False, dataset_pullover_test, device, 1000, 0)\n",
    "pullover_test = np.array([x.cpu().numpy() for x in pullover_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_coat_test = load_dataset(loader_name='fmnist_eval',\n",
    "                                     root=root,\n",
    "                                     label_eval=(4,),\n",
    "                                     test_eval=True)\n",
    "coat_test = oc_encoder.test(False, dataset_coat_test, device, 1000, 0)\n",
    "coat_test = np.array([x.cpu().numpy() for x in coat_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sneaker_test = load_dataset(loader_name='fmnist_eval',\n",
    "                                     root=root,\n",
    "                                     label_eval=(7,),\n",
    "                                     test_eval=True)\n",
    "sneaker_test = oc_encoder.test(False, dataset_sneaker_test, device, 1000, 0)\n",
    "sneaker_test = np.array([x.cpu().numpy() for x in sneaker_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "pullover_coat_train = np.r_[latent_dict_train['oc']['pullover'], latent_dict_train['oc']['coat']]\n",
    "pullover_sneaker_train = np.r_[latent_dict_train['oc']['pullover'], latent_dict_train['oc']['sneaker']]\n",
    "\n",
    "pullover_coat_test_ = np.r_[pullover_test, coat_test]\n",
    "pullover_sneaker_test_ = np.r_[pullover_test, sneaker_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For Pullover & Coat**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Joint Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pullover_coat = {}\n",
    "dict_pullover_coat['coat'] = skl_estimator(pullover_coat_train, pullover_coat_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tshirt 6.678524225035061\n",
      "trouser 7.185524170868892\n",
      "dress 6.070237151115829\n",
      "sandal 7.661263468168078\n",
      "shirt 3.8714684233428267\n",
      "sneaker 7.699502890825909\n",
      "bag 7.41631880409517\n",
      "boot 7.716410785422828\n"
     ]
    }
   ],
   "source": [
    "for x in name_list:\n",
    "    if x in ['coat', 'pullover']:\n",
    "        continue\n",
    "    \n",
    "    joint = np.r_[pullover_test, latent_dict_all['oc'][x]]\n",
    "    kl_ = skl_estimator(pullover_coat_train, joint)\n",
    "    dict_pullover_coat[x] = kl_\n",
    "    print(x, kl_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'coat': 7.661263468168078,\n",
       " 'tshirt': 6.678524225035061,\n",
       " 'trouser': 7.185524170868892,\n",
       " 'dress': 6.070237151115829,\n",
       " 'sandal': 7.661263468168078,\n",
       " 'shirt': 3.8714684233428267,\n",
       " 'sneaker': 7.699502890825909,\n",
       " 'bag': 7.41631880409517,\n",
       " 'boot': 7.716410785422828}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_pullover_coat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Marginal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pullover_coat_ = {}\n",
    "dict_pullover_coat_['training divergence'] = skl_estimator(pullover_train, latent_dict_train['oc']['coat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tshirt 11.072399005169489\n",
      "trouser 18.745953300786717\n",
      "dress 13.76077460303965\n",
      "coat 7.160040157098573\n",
      "sandal 21.11867218781776\n",
      "shirt 4.209448972482385\n",
      "sneaker 23.227279890195163\n",
      "bag 21.15262816948465\n",
      "boot 27.834980624381743\n"
     ]
    }
   ],
   "source": [
    "for x in name_list:\n",
    "    if x in ['pullover']:\n",
    "        continue\n",
    "        \n",
    "    if x in ['coat']:\n",
    "        marginal = coat_test\n",
    "    else:\n",
    "        marginal = latent_dict_all['oc'][x]\n",
    "        \n",
    "    kl_ = skl_estimator(pullover_train, marginal)\n",
    "    dict_pullover_coat_[x] = kl_\n",
    "    print(x, kl_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training divergence': 4.568845462776275,\n",
       " 'tshirt': 11.072399005169489,\n",
       " 'trouser': 18.745953300786717,\n",
       " 'dress': 13.76077460303965,\n",
       " 'coat': 7.160040157098573,\n",
       " 'sandal': 21.11867218781776,\n",
       " 'shirt': 4.209448972482385,\n",
       " 'sneaker': 23.227279890195163,\n",
       " 'bag': 21.15262816948465,\n",
       " 'boot': 27.834980624381743}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_pullover_coat_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For Pullover & Sneaker**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Joint Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pullover_sneaker = {}\n",
    "dict_pullover_sneaker['sneaker'] = skl_estimator(pullover_sneaker_train, pullover_sneaker_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tshirt 27.749288133239418\n",
      "trouser 28.80863523884461\n",
      "dress 27.979325455792644\n",
      "coat 26.085610547476527\n",
      "sandal 12.502880735513374\n",
      "shirt 25.872357051664995\n",
      "bag 21.306602137031792\n",
      "boot 14.474244197800164\n"
     ]
    }
   ],
   "source": [
    "for x in name_list:\n",
    "    if x in ['sneaker', 'pullover']:\n",
    "        continue\n",
    "    \n",
    "    joint = np.r_[pullover_test, latent_dict_all['oc'][x]]\n",
    "    kl_ = skl_estimator(pullover_sneaker_train, joint)\n",
    "    dict_pullover_sneaker[x] = kl_\n",
    "    print(x, kl_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sneaker': 4.945477682473212,\n",
       " 'tshirt': 27.749288133239418,\n",
       " 'trouser': 28.80863523884461,\n",
       " 'dress': 27.979325455792644,\n",
       " 'coat': 26.085610547476527,\n",
       " 'sandal': 12.502880735513374,\n",
       " 'shirt': 25.872357051664995,\n",
       " 'bag': 21.306602137031792,\n",
       " 'boot': 14.474244197800164}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_pullover_sneaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Marginal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pullover_sneaker_ = {}\n",
    "dict_pullover_sneaker_['training divergence'] = skl_estimator(pullover_train, latent_dict_train['oc']['sneaker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tshirt 11.072399005169489\n",
      "trouser 18.745953300786717\n",
      "dress 13.76077460303965\n",
      "coat 4.339410330539567\n",
      "sandal 21.11867218781776\n",
      "shirt 4.209448972482385\n",
      "sneaker 24.12124078252928\n",
      "bag 21.15262816948465\n",
      "boot 27.834980624381743\n"
     ]
    }
   ],
   "source": [
    "for x in name_list:\n",
    "    if x in ['pullover']:\n",
    "        continue\n",
    "        \n",
    "    if x in ['sneaker']:\n",
    "        marginal = sneaker_test\n",
    "    else:\n",
    "        marginal = latent_dict_all['oc'][x]\n",
    "        \n",
    "    kl_ = skl_estimator(pullover_train, marginal)\n",
    "    dict_pullover_sneaker_[x] = kl_\n",
    "    print(x, kl_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training divergence': 23.674082066947456,\n",
       " 'tshirt': 11.072399005169489,\n",
       " 'trouser': 18.745953300786717,\n",
       " 'dress': 13.76077460303965,\n",
       " 'coat': 4.339410330539567,\n",
       " 'sandal': 21.11867218781776,\n",
       " 'shirt': 4.209448972482385,\n",
       " 'sneaker': 24.12124078252928,\n",
       " 'bag': 21.15262816948465,\n",
       " 'boot': 27.834980624381743}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_pullover_sneaker_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## For Reconstruction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "pullover_train = latent_dict_train['rec']['pullover']\n",
    "\n",
    "dataset_pullover_test = load_dataset(loader_name='fmnist_eval',\n",
    "                                     root=root,\n",
    "                                     label_eval=(2,),\n",
    "                                     test_eval=True)\n",
    "pullover_test = rec_encoder.test(False, dataset_pullover_test, device, 1000, 0)\n",
    "pullover_test = np.array([x.cpu().numpy() for x in pullover_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_coat_test = load_dataset(loader_name='fmnist_eval',\n",
    "                                     root=root,\n",
    "                                     label_eval=(4,),\n",
    "                                     test_eval=True)\n",
    "coat_test = rec_encoder.test(False, dataset_coat_test, device, 1000, 0)\n",
    "coat_test = np.array([x.cpu().numpy() for x in coat_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sneaker_test = load_dataset(loader_name='fmnist_eval',\n",
    "                                     root=root,\n",
    "                                     label_eval=(7,),\n",
    "                                     test_eval=True)\n",
    "sneaker_test = rec_encoder.test(False, dataset_sneaker_test, device, 1000, 0)\n",
    "sneaker_test = np.array([x.cpu().numpy() for x in sneaker_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "pullover_coat_train = np.r_[latent_dict_train['rec']['pullover'], latent_dict_train['rec']['coat']]\n",
    "pullover_sneaker_train = np.r_[latent_dict_train['rec']['pullover'], latent_dict_train['rec']['sneaker']]\n",
    "\n",
    "pullover_coat_test_ = np.r_[pullover_test, coat_test]\n",
    "pullover_sneaker_test_ = np.r_[pullover_test, sneaker_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For Pullover & Coat**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Joint Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pullover_coat = {}\n",
    "dict_pullover_coat['coat'] = skl_estimator(pullover_coat_train, pullover_coat_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tshirt 11.120735874828831\n",
      "trouser 11.637051307975428\n",
      "dress 9.935287005951649\n",
      "sandal 12.333502323614523\n",
      "shirt 6.703082442223101\n",
      "sneaker 12.347926201399233\n",
      "bag 11.785093318871137\n",
      "boot 12.351785909246662\n"
     ]
    }
   ],
   "source": [
    "for x in name_list:\n",
    "    if x in ['coat', 'pullover']:\n",
    "        continue\n",
    "    \n",
    "    joint = np.r_[pullover_test, latent_dict_all['rec'][x]]\n",
    "    kl_ = skl_estimator(pullover_coat_train, joint)\n",
    "    dict_pullover_coat[x] = kl_\n",
    "    print(x, kl_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'coat': 5.7802951521432515,\n",
       " 'tshirt': 11.120735874828831,\n",
       " 'trouser': 11.637051307975428,\n",
       " 'dress': 9.935287005951649,\n",
       " 'sandal': 12.333502323614523,\n",
       " 'shirt': 6.703082442223101,\n",
       " 'sneaker': 12.347926201399233,\n",
       " 'bag': 11.785093318871137,\n",
       " 'boot': 12.351785909246662}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_pullover_coat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Marginal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pullover_coat_ = {}\n",
    "dict_pullover_coat_['training divergence'] = skl_estimator(pullover_train, latent_dict_train['rec']['coat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tshirt 22.419006960163852\n",
      "trouser 29.222279733304465\n",
      "dress 25.72757446330517\n",
      "coat 13.3593069721264\n",
      "sandal 42.72670602945978\n",
      "shirt 8.374302806296916\n",
      "sneaker 51.56025831856643\n",
      "bag 27.437054142348256\n",
      "boot 42.617041903532666\n"
     ]
    }
   ],
   "source": [
    "for x in name_list:\n",
    "    if x in ['pullover']:\n",
    "        continue\n",
    "        \n",
    "    if x in ['coat']:\n",
    "        marginal = coat_test\n",
    "    else:\n",
    "        marginal = latent_dict_all['rec'][x]\n",
    "        \n",
    "    kl_ = skl_estimator(pullover_train, marginal)\n",
    "    dict_pullover_coat_[x] = kl_\n",
    "    print(x, kl_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training divergence': 8.94335837191094,\n",
       " 'tshirt': 22.419006960163852,\n",
       " 'trouser': 29.222279733304465,\n",
       " 'dress': 25.72757446330517,\n",
       " 'coat': 13.3593069721264,\n",
       " 'sandal': 42.72670602945978,\n",
       " 'shirt': 8.374302806296916,\n",
       " 'sneaker': 51.56025831856643,\n",
       " 'bag': 27.437054142348256,\n",
       " 'boot': 42.617041903532666}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_pullover_coat_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For Pullover & Sneaker**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Joint Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pullover_sneaker = {}\n",
    "dict_pullover_sneaker['sneaker'] = skl_estimator(pullover_sneaker_train, pullover_sneaker_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tshirt 27.240742390932915\n",
      "trouser 32.03923934051166\n",
      "dress 30.509918074422842\n",
      "coat 28.90765698237408\n",
      "sandal 11.615368704008327\n",
      "shirt 25.05988784523028\n",
      "bag 18.78444655946627\n",
      "boot 13.841945709052613\n"
     ]
    }
   ],
   "source": [
    "for x in name_list:\n",
    "    if x in ['sneaker', 'pullover']:\n",
    "        continue\n",
    "    \n",
    "    joint = np.r_[pullover_test, latent_dict_all['rec'][x]]\n",
    "    kl_ = skl_estimator(pullover_sneaker_train, joint)\n",
    "    dict_pullover_sneaker[x] = kl_\n",
    "    print(x, kl_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sneaker': 5.553674691659444,\n",
       " 'tshirt': 27.240742390932915,\n",
       " 'trouser': 32.03923934051166,\n",
       " 'dress': 30.509918074422842,\n",
       " 'coat': 28.90765698237408,\n",
       " 'sandal': 11.615368704008327,\n",
       " 'shirt': 25.05988784523028,\n",
       " 'bag': 18.78444655946627,\n",
       " 'boot': 13.841945709052613}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_pullover_sneaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Marginal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pullover_sneaker_ = {}\n",
    "dict_pullover_sneaker_['training divergence'] = skl_estimator(pullover_train, latent_dict_train['rec']['sneaker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tshirt 22.419006960163852\n",
      "trouser 29.222279733304465\n",
      "dress 25.72757446330517\n",
      "coat 8.561594577078122\n",
      "sandal 42.72670602945978\n",
      "shirt 8.374302806296916\n",
      "sneaker 58.13651305406425\n",
      "bag 27.437054142348256\n",
      "boot 42.617041903532666\n"
     ]
    }
   ],
   "source": [
    "for x in name_list:\n",
    "    if x in ['pullover']:\n",
    "        continue\n",
    "        \n",
    "    if x in ['sneaker']:\n",
    "        marginal = sneaker_test\n",
    "    else:\n",
    "        marginal = latent_dict_all['rec'][x]\n",
    "        \n",
    "    kl_ = skl_estimator(pullover_train, marginal)\n",
    "    dict_pullover_sneaker_[x] = kl_\n",
    "    print(x, kl_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training divergence': 51.440300511933614,\n",
       " 'tshirt': 22.419006960163852,\n",
       " 'trouser': 29.222279733304465,\n",
       " 'dress': 25.72757446330517,\n",
       " 'coat': 8.561594577078122,\n",
       " 'sandal': 42.72670602945978,\n",
       " 'shirt': 8.374302806296916,\n",
       " 'sneaker': 58.13651305406425,\n",
       " 'bag': 27.437054142348256,\n",
       " 'boot': 42.617041903532666}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_pullover_sneaker_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
