{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTLoader(BaseDataset):\n",
    "    def __init__(self,\n",
    "                 root: str='/net/leksai/data/FashionMNIST',\n",
    "                 label_normal: tuple=(0,),\n",
    "                 label_abnormal: tuple=(),  # If unsupervised, do not specify\n",
    "                 ratio_abnormal: float=0.1):\n",
    "        super().__init__(root)\n",
    "\n",
    "        # Initialization\n",
    "        self.root = root\n",
    "        self.label_normal = label_normal\n",
    "        self.label_abnormal = label_abnormal\n",
    "        self.ratio_abnormal = ratio_abnormal\n",
    "\n",
    "        # Read in initial Full Set\n",
    "        # Add in download=True if you haven't downloaded yet\n",
    "        print('Loading dataset for you!')\n",
    "        train_set = FashionMNISTDataset(root=root, train=True, transform=transforms.ToTensor(), download=True)\n",
    "        test_set = FashionMNISTDataset(root=root, train=False, transform=transforms.ToTensor(), download=True)\n",
    "        print('Almost loaded!')\n",
    "\n",
    "        # Get the labels for classes intended to use\n",
    "        y_train = train_set.targets.cpu().data.numpy()\n",
    "        y_test = test_set.targets.cpu().data.numpy()\n",
    "\n",
    "        # Get the indices for classes intended to use\n",
    "        train_idx = self.get_idx(y_train, label_normal, label_abnormal, ratio_abnormal, True)\n",
    "        test_idx = self.get_idx(y_test, label_normal, label_abnormal, ratio_abnormal, False)\n",
    "\n",
    "        # Get the subset\n",
    "        self.train_set = Subset(train_set, train_idx)\n",
    "        self.test_set = Subset(test_set, test_idx)\n",
    "\n",
    "    def get_idx(self, y, label_normal, label_abnormal, ratio_abnormal, train):\n",
    "        \"\"\"\n",
    "        Creat a numpy list of indices of label_ in labels.\n",
    "        Inputs:\n",
    "            y (np.array): dataset.targets.cpu().data.numpy()\n",
    "            label_normal (tuple): e.g. (0,)\n",
    "            label_abnormal (tuple): e.g. (1,)\n",
    "            ratio_abnormal (float): e.g. 0.1\n",
    "            train (bool): True / False\n",
    "        \"\"\"\n",
    "        idx_normal = np.argwhere(np.isin(y, label_normal)).flatten()\n",
    "\n",
    "        if label_abnormal:\n",
    "            idx_abnormal = np.argwhere(np.isin(y, label_abnormal)).flatten()\n",
    "            np.random.shuffle(idx_abnormal)\n",
    "            if train:\n",
    "                idx_abnormal = idx_abnormal[:int(len(idx_abnormal) * ratio_abnormal)]\n",
    "            idx_all = np.hstack((idx_normal, idx_abnormal))\n",
    "        else:\n",
    "            idx_all = idx_normal\n",
    "        return idx_all\n",
    "\n",
    "    def loaders(self,\n",
    "                batch_size: int,\n",
    "                shuffle_train=True,\n",
    "                shuffle_test=False,\n",
    "                num_workers: int = 0) -> (DataLoader, DataLoader):\n",
    "        train_loader = DataLoader(dataset=self.train_set,\n",
    "                                  batch_size=batch_size,\n",
    "                                  shuffle=shuffle_train,\n",
    "                                  num_workers=num_workers,\n",
    "                                  drop_last=True)\n",
    "        test_loader = DataLoader(dataset=self.test_set,\n",
    "                                 batch_size=batch_size,\n",
    "                                 shuffle=shuffle_test,\n",
    "                                 num_workers=num_workers,\n",
    "                                 drop_last=False)\n",
    "        return train_loader, test_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset for you!\n",
      "Almost loaded!\n"
     ]
    }
   ],
   "source": [
    "dataset = FashionMNISTLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, loader = dataset.loaders(batch_size=batch_size_loading,\n",
    "                         num_workers=num_workers)\n",
    "for data in loader:\n",
    "    X, y, idx = data\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.2039, 0.7529, 0.4510, 0.1059, 0.0039, 0.0039, 0.1216,\n",
       "           0.5608, 0.7020, 0.1255, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0196, 0.4431,\n",
       "           0.7255, 0.8471, 0.7451, 0.8980, 0.9294, 0.8627, 0.8510, 0.9490,\n",
       "           0.7882, 0.7490, 0.8706, 0.6549, 0.3412, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1961, 0.6863, 0.7608,\n",
       "           0.7412, 0.7294, 0.7255, 0.7333, 0.7804, 0.7373, 0.7216, 0.7569,\n",
       "           0.7255, 0.7373, 0.7176, 0.7333, 0.7569, 0.8235, 0.0588, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7804, 0.7608, 0.7098,\n",
       "           0.7373, 0.7451, 0.7412, 0.7373, 0.7529, 0.7804, 0.7725, 0.7647,\n",
       "           0.7529, 0.7490, 0.7373, 0.7216, 0.6941, 0.7412, 0.6980, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.1882, 0.7608, 0.7412, 0.7412,\n",
       "           0.7569, 0.7412, 0.7412, 0.7373, 0.7373, 0.7490, 0.7490, 0.7451,\n",
       "           0.7569, 0.7451, 0.7373, 0.7294, 0.7608, 0.7216, 0.7412, 0.1647,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.7608, 0.8941, 0.7686, 0.7451,\n",
       "           0.7412, 0.7490, 0.6941, 0.6941, 0.7098, 0.7333, 0.7294, 0.7216,\n",
       "           0.7059, 0.7098, 0.7373, 0.7529, 0.7373, 0.7333, 0.7490, 0.4941,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.8588, 0.9333, 0.8039, 0.7451,\n",
       "           0.7451, 0.7020, 0.7529, 0.8627, 0.8196, 0.8784, 0.9059, 0.8627,\n",
       "           0.8902, 0.8078, 0.7216, 0.7412, 0.7373, 0.7686, 0.7294, 0.7451,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.2588, 0.9216, 0.8824, 0.7922, 0.7373,\n",
       "           0.7451, 0.8667, 0.8392, 0.7412, 0.6314, 0.6627, 0.7490, 0.6902,\n",
       "           0.8118, 0.7608, 0.9373, 0.7490, 0.7255, 0.7686, 0.7216, 0.6980,\n",
       "           0.1843, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.5137, 0.9529, 0.8510, 0.7765, 0.7333,\n",
       "           0.8980, 0.7020, 0.6706, 0.6471, 0.6314, 0.6784, 0.6863, 0.6196,\n",
       "           0.6863, 0.4667, 0.7020, 0.9373, 0.7098, 0.7529, 0.7451, 0.7686,\n",
       "           0.4510, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.4196, 0.8824, 1.0000, 0.7373,\n",
       "           0.8275, 0.6824, 0.4824, 0.8745, 0.8667, 0.8941, 0.9412, 0.8510,\n",
       "           0.8275, 0.5882, 0.8627, 0.8392, 0.7255, 0.8431, 0.8196, 0.2784,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3882, 0.8588,\n",
       "           0.7294, 0.8863, 0.9216, 0.8863, 0.7765, 0.7451, 0.7294, 0.7686,\n",
       "           0.8275, 0.8784, 0.9020, 0.7216, 0.8196, 0.4510, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0039, 0.0078, 0.0000, 0.0000, 0.8588,\n",
       "           0.7804, 0.7569, 0.8000, 0.7216, 0.7451, 0.7529, 0.7647, 0.7373,\n",
       "           0.8314, 0.9059, 0.8902, 0.8510, 0.7647, 0.0000, 0.0000, 0.0118,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.8706,\n",
       "           0.7765, 0.7686, 0.7647, 0.7725, 0.7608, 0.7569, 0.7765, 0.7176,\n",
       "           0.8941, 0.9569, 0.8902, 0.8471, 0.7647, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.8510,\n",
       "           0.7725, 0.7686, 0.7804, 0.7725, 0.7647, 0.7725, 0.7647, 0.7608,\n",
       "           0.7882, 0.9098, 0.8902, 0.8196, 0.7176, 0.0000, 0.0000, 0.0039,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.8510,\n",
       "           0.7725, 0.7725, 0.7804, 0.7765, 0.7765, 0.7804, 0.7686, 0.7922,\n",
       "           0.7490, 0.7569, 0.7647, 0.7725, 0.7216, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.8431,\n",
       "           0.7765, 0.7765, 0.7804, 0.7804, 0.7882, 0.7882, 0.7765, 0.7882,\n",
       "           0.7725, 0.7569, 0.7255, 0.7765, 0.7176, 0.0000, 0.0000, 0.0039,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.8314,\n",
       "           0.7804, 0.7765, 0.7765, 0.7882, 0.7922, 0.7922, 0.7725, 0.7804,\n",
       "           0.7765, 0.7765, 0.7451, 0.7804, 0.7176, 0.0000, 0.0000, 0.0039,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.8392,\n",
       "           0.7882, 0.7804, 0.7804, 0.7882, 0.7922, 0.7922, 0.7804, 0.7882,\n",
       "           0.7765, 0.7725, 0.7490, 0.7765, 0.7255, 0.0000, 0.0000, 0.0039,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.8471,\n",
       "           0.7961, 0.7804, 0.7882, 0.7922, 0.8000, 0.7922, 0.7804, 0.7882,\n",
       "           0.7765, 0.7725, 0.7569, 0.7686, 0.7490, 0.0000, 0.0000, 0.0039,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.8510,\n",
       "           0.7922, 0.7725, 0.7961, 0.7922, 0.7922, 0.8000, 0.7961, 0.7922,\n",
       "           0.7882, 0.7765, 0.7647, 0.7647, 0.7882, 0.0000, 0.0000, 0.0039,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.0000, 0.8510,\n",
       "           0.7804, 0.7725, 0.8039, 0.7961, 0.7961, 0.8000, 0.7922, 0.7922,\n",
       "           0.7922, 0.7804, 0.7647, 0.7647, 0.8000, 0.0000, 0.0000, 0.0039,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.8667,\n",
       "           0.7765, 0.7765, 0.8000, 0.7922, 0.7922, 0.7961, 0.7882, 0.7804,\n",
       "           0.7882, 0.7804, 0.7647, 0.7686, 0.7765, 0.0000, 0.0000, 0.0039,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.8784,\n",
       "           0.7765, 0.7882, 0.7882, 0.7804, 0.7804, 0.7922, 0.7882, 0.7804,\n",
       "           0.7804, 0.7804, 0.7647, 0.7686, 0.7608, 0.0000, 0.0000, 0.0039,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0431, 0.7490,\n",
       "           0.7608, 0.7961, 0.7882, 0.7804, 0.7725, 0.7765, 0.7804, 0.7765,\n",
       "           0.7765, 0.7765, 0.7804, 0.7765, 0.7647, 0.0000, 0.0000, 0.0039,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0431, 0.7569,\n",
       "           0.7686, 0.7882, 0.7686, 0.7686, 0.7686, 0.7686, 0.7725, 0.7765,\n",
       "           0.7765, 0.7725, 0.7765, 0.7765, 0.8000, 0.0000, 0.0000, 0.0039,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0392, 0.7490,\n",
       "           0.7686, 0.7569, 0.7569, 0.7608, 0.7725, 0.7647, 0.7647, 0.7725,\n",
       "           0.7725, 0.7686, 0.7608, 0.7725, 0.7804, 0.0000, 0.0000, 0.0039,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.0431, 0.7765,\n",
       "           0.8000, 0.8039, 0.7882, 0.7725, 0.7765, 0.7569, 0.7490, 0.7647,\n",
       "           0.7765, 0.7922, 0.7961, 0.8078, 0.8706, 0.0000, 0.0000, 0.0039,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.6863,\n",
       "           0.7059, 0.6588, 0.7569, 0.7922, 0.7922, 0.7608, 0.7647, 0.7922,\n",
       "           0.8078, 0.7647, 0.7333, 0.6784, 0.5804, 0.0000, 0.0000, 0.0039,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from abc import ABC, abstractmethod\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import ConcatDataset\n",
    "from torchvision.datasets import KMNIST\n",
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "# #########################################################################\n",
    "# 1. Base Dataset\n",
    "# #########################################################################\n",
    "class BaseDataset(ABC):\n",
    "    def __init__(self, root: str):\n",
    "        super().__init__()\n",
    "\n",
    "        self.root = root\n",
    "        self.label_normal = ()\n",
    "        self.label_abnormal = ()\n",
    "        self.train_set = None\n",
    "        self.test_set = None\n",
    "\n",
    "    @abstractmethod\n",
    "    def loaders(self,\n",
    "                batch_size: int,\n",
    "                shuffle_train=True,\n",
    "                shuffle_test=False,\n",
    "                num_workers: int = 0):\n",
    "        pass\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMNISTDataset(KMNIST):\n",
    "    \"\"\"\n",
    "    Add an index to get item.\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.data[index], int(self.targets[index])\n",
    "        img = Image.fromarray(img.numpy(), mode='L')\n",
    "        transform = transforms.ToTensor()\n",
    "        img = transform(img)\n",
    "        return img, int(target), index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/net/leksai/data/KMNIST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/net/leksai/data/KMNIST'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = KMNISTDataset(root=root, train=True, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = KMNISTDataset(root=root, train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_set,\n",
    "                                  batch_size=128,\n",
    "                                  shuffle=True,\n",
    "                                  num_workers=num_workers,\n",
    "                                  drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train_loader:\n",
    "    X, y, idx = data\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABQElEQVR4nHWSvUvDYBDGn9ikH1ao0cFWFIQSuhXEwc0q6iL4B4hoh65OQgQnB3F1qboJ4tJJqJODIKiFCDqpdKhQHCqFogENwVRJzikkNZeb7r0f99zdwwt4sZXF6r4MPs53x006y0QkDtbsa3KOxCAQAKhEn1fJENmheyoJ/kKfL9fL0CkMogsDYhhMQ4IdBt/hgDgoKQkIiPds6MKR6uPDbAcDPdCdn5++6L/8Ro7ttAYTS+tR8M5GtC8ZKh2wECUqIvq0zUPFasZQmEDycCUVpCe0CCCr0c+du4hnQh05YPg03+5UnX+nAG+QhXl1kirl16BsgRrHv05zht1omYioPuYveTPTAGijxd8yqhHVBJ4BikObEFIZTha6jZc1rXHD+htvfxgOmc/e//N1WnutnQUjdmvyU6fEYpfmvPcfNzlmNj5WYP0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FD4F03A30F0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "untransform = transforms.ToPILImage()\n",
    "X_mean = torch.mean(X, axis=0)\n",
    "img = untransform(X_mean);  display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 28])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABiUlEQVR4nLWRPUhbURiGn/vTa9JgQ5pYVOLY0mggxMahGYQM7SA4uDRNJXZpnRy0BSEVCa5xCiVQOlhFS7t0qaBiHURKuhWqOIkIgiBoMDH+tDe993S4gfyYsX7Lec/3fO97zuHAtZRUkZ5HlL7qjcfsM0Lk3Y2Z/CI3ORCoa6pN1hotxa86HK96AKTFKbn2CgDDtiDA3T0v+N4ufvh0uwo6mwF4ciy3Zdb7ggmRvhJue/4r9iOswKAottTDhDAW3AAP/5hDdcy9KZYs1a+fB2vZnRXDSFnyvfhY6cuANhIayxoAKBHe1fjalvW4nBoF4NbJ7o0qp9Sdicx9Nu+bAHTcPCpVoPp0Vlt9XWL/EgCX8bsqU32pbcddpxxazi77VhlInf5W9SA5rWdOvvgFAN+KHo8kit57vmggO4xbg/afhbPHliEt/ur5w0uR2+hVyxnB/FYUaA4prjUhxMXOG3/V0fNmGvCZ4zgnks/alZq3PigsSeAT3+s+1KpOB+CMha2dojWa+V/1D7NAc22SeuCVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FD4F03A36D8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_0 = X[2]\n",
    "img = untransform(X_0);  display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMNISTLoader(BaseDataset):\n",
    "    def __init__(self,\n",
    "                 root: str='/net/leksai/data/KMNIST',\n",
    "                 label_normal: tuple=(0,),\n",
    "                 label_abnormal: tuple=(),  # If unsupervised, do not specify\n",
    "                 ratio_abnormal: float=0.1):\n",
    "        super().__init__(root)\n",
    "\n",
    "        # Initialization\n",
    "        self.root = root\n",
    "        self.label_normal = label_normal\n",
    "        self.label_abnormal = label_abnormal\n",
    "        self.ratio_abnormal = ratio_abnormal\n",
    "\n",
    "        # Read in initial Full Set\n",
    "        # Add in download=True if you haven't downloaded yet\n",
    "        print('Loading dataset for you!')\n",
    "        train_set = KMNISTDataset(root=root, train=True, transform=transforms.ToTensor(), download=True)\n",
    "        test_set = KMNISTDataset(root=root, train=False, transform=transforms.ToTensor(), download=True)\n",
    "        print('Almost loaded!')\n",
    "\n",
    "        # Get the labels for classes intended to use\n",
    "        y_train = train_set.targets.cpu().data.numpy()\n",
    "        y_test = test_set.targets.cpu().data.numpy()\n",
    "\n",
    "        # Get the indices for classes intended to use\n",
    "        train_idx = self.get_idx(y_train, label_normal, label_abnormal, ratio_abnormal, True)\n",
    "        test_idx = self.get_idx(y_test, label_normal, label_abnormal, ratio_abnormal, False)\n",
    "\n",
    "        # Get the subset\n",
    "        self.train_set = Subset(train_set, train_idx)\n",
    "        self.test_set = Subset(test_set, test_idx)\n",
    "\n",
    "    def get_idx(self, y, label_normal, label_abnormal, ratio_abnormal, train):\n",
    "        \"\"\"\n",
    "        Creat a numpy list of indices of label_ in labels.\n",
    "        Inputs:\n",
    "            y (np.array): dataset.targets.cpu().data.numpy()\n",
    "            label_normal (tuple): e.g. (0,)\n",
    "            label_abnormal (tuple): e.g. (1,)\n",
    "            ratio_abnormal (float): e.g. 0.1\n",
    "            train (bool): True / False\n",
    "        \"\"\"\n",
    "        idx_normal = np.argwhere(np.isin(y, label_normal)).flatten()\n",
    "\n",
    "        if label_abnormal:\n",
    "            idx_abnormal = np.argwhere(np.isin(y, label_abnormal)).flatten()\n",
    "            np.random.shuffle(idx_abnormal)\n",
    "            if train:\n",
    "                idx_abnormal = idx_abnormal[:int(len(idx_abnormal) * ratio_abnormal)]\n",
    "            idx_all = np.hstack((idx_normal, idx_abnormal))\n",
    "        else:\n",
    "            idx_all = idx_normal\n",
    "        return idx_all\n",
    "\n",
    "    def loaders(self,\n",
    "                batch_size: int,\n",
    "                shuffle_train=True,\n",
    "                shuffle_test=False,\n",
    "                num_workers: int = 0) -> (DataLoader, DataLoader):\n",
    "        train_loader = DataLoader(dataset=self.train_set,\n",
    "                                  batch_size=batch_size,\n",
    "                                  shuffle=shuffle_train,\n",
    "                                  num_workers=num_workers,\n",
    "                                  drop_last=True)\n",
    "        test_loader = DataLoader(dataset=self.test_set,\n",
    "                                 batch_size=batch_size,\n",
    "                                 shuffle=shuffle_test,\n",
    "                                 num_workers=num_workers,\n",
    "                                 drop_last=False)\n",
    "        return train_loader, test_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMNISTLoaderEval(BaseDataset):\n",
    "    def __init__(self,\n",
    "                 root: str='/net/leksai/data/KMNIST',\n",
    "                 label: tuple=(),\n",
    "                 test_eval: bool=False):\n",
    "        super().__init__(root)\n",
    "\n",
    "        # Initialization\n",
    "        self.root = root\n",
    "        self.label = label\n",
    "\n",
    "        # Read in initial Full Set\n",
    "        # Add in download=True if you haven't downloaded yet\n",
    "        train_set = KMNISTDataset(root=root, train=True, transform=transforms.ToTensor(), download=True)\n",
    "        test_set = KMNISTDataset(root=root, train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "        # Get the labels for classes intended to use\n",
    "        y_train = train_set.targets.cpu().data.numpy()\n",
    "        y_test = test_set.targets.cpu().data.numpy()\n",
    "\n",
    "        # Get the indices for classes intended to use\n",
    "        train_idx = self.get_idx(y_train, label)\n",
    "        test_idx = self.get_idx(y_test, label)\n",
    "\n",
    "        # Get the subset\n",
    "        train_set = Subset(train_set, train_idx)\n",
    "        test_set = Subset(test_set, test_idx)\n",
    "        if test_eval:\n",
    "            self.all_set = test_set\n",
    "        else:\n",
    "            self.all_set = ConcatDataset((train_set, test_set))\n",
    "\n",
    "    def get_idx(self, y, label):\n",
    "        \"\"\"\n",
    "        Creat a numpy list of indices of label_ in labels.\n",
    "        Inputs:\n",
    "            y (np.array): dataset.targets.cpu().data.numpy()\n",
    "            label (tuple): e.g. (0,)\n",
    "        \"\"\"\n",
    "        return np.argwhere(np.isin(y, label)).flatten()\n",
    "\n",
    "    def loaders(self,\n",
    "                batch_size: int,\n",
    "                shuffle=False,\n",
    "                num_workers: int = 0):\n",
    "        all_loader = DataLoader(dataset=self.all_set,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=shuffle,\n",
    "                                num_workers=num_workers,\n",
    "                                drop_last=False)\n",
    "        return all_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = KMNISTLoaderEval(label = (6,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_loading = 7000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAB4ElEQVR4nD3SS5LjRhADUCArqyhSUvdovLDvfzGfwNExalL8VSa8kMfrFwA2IACSxd2H6eNzyuc/X68zUgLgAEnSSh3Gjz//Gr7+VmQCeCNIM6/VYjv8pz+/lrNTbyRJq+1SjZCNMV2n/UxC/9UWb+PYSruPl0sfr9N6/L8Js9LG23Uaxx/3yzmO19cWYuh3sg63x+M2TLdW23gZhq6ulAM0Myvt+nGv1Vlqa8NwpiQ5SJqp954hdZl7KcXrG0Ej4ljXBVY/YcUIkCUzHKQZ0Y99JScYlRGCWQk6WIqZlP2warXoWPczUjQzI80KCWUEasU+P5f9TNEMDrNiVJz7ZhV5Lr+e89YTAOi0Qii1LQyu5/6a5/UIgQCcRiIjaIQfve/b0d8mOQhldtCPQcroKZCgJDgAIQTA6tBMonsEEKl0AJJgpY23+3VgacOgMyUlHBBA8zbeH388LunTde+JnikZBIAsbfp8/PwcShunoRoyI2Hvt5jVy3SdGlUuQyvMTOE3giSA2A+UWpgZCcAhSWJE39fFaj9SGb1HCnApUwk7t/U1q8a8bMfRe0qAKwIIcFtfs4cf38/v13b0SAmu6EIorQ5Ne9mW71/zdvRUSo48A1LSLPeb7a95XvYeKQj/Am1OSAPlbjU6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FD4F0416E48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loader = dataset.loaders(batch_size=batch_size_loading,\n",
    "                         num_workers=num_workers)\n",
    "for data in loader:\n",
    "    X, y, idx = data\n",
    "    break\n",
    "    \n",
    "X_mean = torch.mean(X, axis=0)\n",
    "img = untransform(X_mean); display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7000, 1, 28, 28])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Title: fmnist_loader.py\n",
    "Description: The loader classes for the FashionMNIST datasets\n",
    "Author: Lek'Sai Ye, University of Chicago\n",
    "\"\"\"\n",
    "\n",
    "from PIL import Image\n",
    "from abc import ABC, abstractmethod\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import ConcatDataset\n",
    "from torchvision.datasets import KMNIST\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "# #########################################################################\n",
    "# 1. Base Dataset\n",
    "# #########################################################################\n",
    "class BaseDataset(ABC):\n",
    "    def __init__(self, root: str):\n",
    "        super().__init__()\n",
    "\n",
    "        self.root = root\n",
    "        self.label_normal = ()\n",
    "        self.label_abnormal = ()\n",
    "        self.train_set = None\n",
    "        self.test_set = None\n",
    "\n",
    "    @abstractmethod\n",
    "    def loaders(self,\n",
    "                batch_size: int,\n",
    "                shuffle_train=True,\n",
    "                shuffle_test=False,\n",
    "                num_workers: int = 0):\n",
    "        pass\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__\n",
    "\n",
    "\n",
    "# #########################################################################\n",
    "# 2. FashionMNIST Dataset\n",
    "# #########################################################################\n",
    "class FashionMNISTDataset(FashionMNIST):\n",
    "    \"\"\"\n",
    "    Add an index to get item.\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.data[index], int(self.targets[index])\n",
    "        img = Image.fromarray(img.numpy(), mode='L')\n",
    "        transform = transforms.ToTensor()\n",
    "        img = transform(img)\n",
    "        return img, int(target), index\n",
    "\n",
    "\n",
    "# #########################################################################\n",
    "# 2. FashionMNIST Loader for Training\n",
    "# #########################################################################\n",
    "class FashionMNISTLoader(BaseDataset):\n",
    "    def __init__(self,\n",
    "                 root: str='/net/leksai/data/FashionMNIST',\n",
    "                 label_normal: tuple=(0,),\n",
    "                 label_abnormal: tuple=(),  # If unsupervised, do not specify\n",
    "                 ratio_abnormal: float=0.1):\n",
    "        super().__init__(root)\n",
    "\n",
    "        # Initialization\n",
    "        self.root = root\n",
    "        self.label_normal = label_normal\n",
    "        self.label_abnormal = label_abnormal\n",
    "        self.ratio_abnormal = ratio_abnormal\n",
    "\n",
    "        # Read in initial Full Set\n",
    "        # Add in download=True if you haven't downloaded yet\n",
    "        print('Loading dataset for you!')\n",
    "        train_set = FashionMNISTDataset(root=root, train=True, transform=transforms.ToTensor(), download=True)\n",
    "        test_set = FashionMNISTDataset(root=root, train=False, transform=transforms.ToTensor(), download=True)\n",
    "        print('Almost loaded!')\n",
    "\n",
    "        # Get the labels for classes intended to use\n",
    "        y_train = train_set.targets.cpu().data.numpy()\n",
    "        y_test = test_set.targets.cpu().data.numpy()\n",
    "\n",
    "        # Get the indices for classes intended to use\n",
    "        train_idx = self.get_idx(y_train, label_normal, label_abnormal, ratio_abnormal, True)\n",
    "        test_idx = self.get_idx(y_test, label_normal, label_abnormal, ratio_abnormal, False)\n",
    "\n",
    "        # Get the subset\n",
    "        self.train_set = Subset(train_set, train_idx)\n",
    "        self.test_set = Subset(test_set, test_idx)\n",
    "\n",
    "    def get_idx(self, y, label_normal, label_abnormal, ratio_abnormal, train):\n",
    "        \"\"\"\n",
    "        Creat a numpy list of indices of label_ in labels.\n",
    "        Inputs:\n",
    "            y (np.array): dataset.targets.cpu().data.numpy()\n",
    "            label_normal (tuple): e.g. (0,)\n",
    "            label_abnormal (tuple): e.g. (1,)\n",
    "            ratio_abnormal (float): e.g. 0.1\n",
    "            train (bool): True / False\n",
    "        \"\"\"\n",
    "        idx_normal = np.argwhere(np.isin(y, label_normal)).flatten()\n",
    "\n",
    "        if label_abnormal:\n",
    "            idx_abnormal = np.argwhere(np.isin(y, label_abnormal)).flatten()\n",
    "            np.random.shuffle(idx_abnormal)\n",
    "            if train:\n",
    "                idx_abnormal = idx_abnormal[:int(len(idx_abnormal) * ratio_abnormal)]\n",
    "            idx_all = np.hstack((idx_normal, idx_abnormal))\n",
    "        else:\n",
    "            idx_all = idx_normal\n",
    "        return idx_all\n",
    "\n",
    "    def loaders(self,\n",
    "                batch_size: int,\n",
    "                shuffle_train=True,\n",
    "                shuffle_test=False,\n",
    "                num_workers: int = 0) -> (DataLoader, DataLoader):\n",
    "        train_loader = DataLoader(dataset=self.train_set,\n",
    "                                  batch_size=batch_size,\n",
    "                                  shuffle=shuffle_train,\n",
    "                                  num_workers=num_workers,\n",
    "                                  drop_last=True)\n",
    "        test_loader = DataLoader(dataset=self.test_set,\n",
    "                                 batch_size=batch_size,\n",
    "                                 shuffle=shuffle_test,\n",
    "                                 num_workers=num_workers,\n",
    "                                 drop_last=False)\n",
    "        return train_loader, test_loader\n",
    "\n",
    "\n",
    "# #########################################################################\n",
    "# 2. FashionMNIST Loader for Evaluation\n",
    "# #########################################################################\n",
    "class FashionMNISTLoaderEval(BaseDataset):\n",
    "    def __init__(self,\n",
    "                 root: str='/net/leksai/data/FashionMNIST',\n",
    "                 label: tuple=(),\n",
    "                 test_eval: bool=False):\n",
    "        super().__init__(root)\n",
    "\n",
    "        # Initialization\n",
    "        self.root = root\n",
    "        self.label = label\n",
    "\n",
    "        # Read in initial Full Set\n",
    "        # Add in download=True if you haven't downloaded yet\n",
    "        train_set = FashionMNISTDataset(root=root, train=True, transform=transforms.ToTensor(), download=True)\n",
    "        test_set = FashionMNISTDataset(root=root, train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "        # Get the labels for classes intended to use\n",
    "        y_train = train_set.targets.cpu().data.numpy()\n",
    "        y_test = test_set.targets.cpu().data.numpy()\n",
    "\n",
    "        # Get the indices for classes intended to use\n",
    "        train_idx = self.get_idx(y_train, label)\n",
    "        test_idx = self.get_idx(y_test, label)\n",
    "\n",
    "        # Get the subset\n",
    "        train_set = Subset(train_set, train_idx)\n",
    "        test_set = Subset(test_set, test_idx)\n",
    "        if test_eval:\n",
    "            self.all_set = test_set\n",
    "        else:\n",
    "            self.all_set = ConcatDataset((train_set, test_set))\n",
    "\n",
    "    def get_idx(self, y, label):\n",
    "        \"\"\"\n",
    "        Creat a numpy list of indices of label_ in labels.\n",
    "        Inputs:\n",
    "            y (np.array): dataset.targets.cpu().data.numpy()\n",
    "            label (tuple): e.g. (0,)\n",
    "        \"\"\"\n",
    "        return np.argwhere(np.isin(y, label)).flatten()\n",
    "\n",
    "    def loaders(self,\n",
    "                batch_size: int,\n",
    "                shuffle=False,\n",
    "                num_workers: int = 0):\n",
    "        all_loader = DataLoader(dataset=self.all_set,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=shuffle,\n",
    "                                num_workers=num_workers,\n",
    "                                drop_last=False)\n",
    "        return all_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
